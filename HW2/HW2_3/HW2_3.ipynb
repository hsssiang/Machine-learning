{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Q2-3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6212faf1f2dc30da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d279ec825d640161"
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as  np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "import warnings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T18:10:56.132343Z",
     "start_time": "2023-10-20T18:10:56.104132Z"
    }
   },
   "id": "aaa6be23f8045bdc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data import"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c21c18c89df6cdd3"
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN in the Data\n",
      "satisfaction_level       0\n",
      "last_evaluation          0\n",
      "number_project           0\n",
      "average_montly_hours     0\n",
      "time_spend_company       0\n",
      "Work_accident            0\n",
      "promotion_last_5years    0\n",
      "sales                    0\n",
      "salary                   0\n",
      "left                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "pd.set_option ( \"display.max_rows\", 20000 )\n",
    "pd.set_option ( \"display.max_columns\", 20 )\n",
    "usecols_data = ['satisfaction_level','last_evaluation','number_project','average_montly_hours','time_spend_company','Work_accident','promotion_last_5years','sales','salary']\n",
    "df_data_all = pd.read_csv( r'HW2_data/HW2_hr-analytics_train.csv' )\n",
    "print ( \"Number of NaN in the Data\" )\n",
    "print ( df_data_all.isna().sum() )\n",
    "df_data = pd.read_csv( r'HW2_data/HW2_hr-analytics_train.csv' , usecols = usecols_data )\n",
    "df_label = pd.read_csv( r'HW2_data/HW2_hr-analytics_train.csv' , usecols = ['left'] )\n",
    "df_test = pd.read_csv( r'HW2_data/HW2_hr-analytics_test.csv' )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T18:10:56.205051Z",
     "start_time": "2023-10-20T18:10:56.113417Z"
    }
   },
   "id": "699b3d853de8c296"
  },
  {
   "cell_type": "markdown",
   "source": [
    "各個特徵與離職率的關係探討"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "214d361d5949104f"
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left                     1.000000\n",
      "satisfaction_level       0.389721\n",
      "Work_accident            0.158327\n",
      "time_spend_company       0.138764\n",
      "average_montly_hours     0.069911\n",
      "promotion_last_5years    0.064861\n",
      "number_project           0.023949\n",
      "last_evaluation          0.008456\n",
      "Name: left, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_data_all_drop = df_data_all.select_dtypes(include = [\"int64\", \"float64\" ])\n",
    "correlation_matrix = df_data_all_drop.corr()\n",
    "correlation_with_target = correlation_matrix['left']\n",
    "print(correlation_with_target.abs().sort_values(ascending=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T18:10:56.205286Z",
     "start_time": "2023-10-20T18:10:56.163078Z"
    }
   },
   "id": "7b6f8db400bcc603"
  },
  {
   "cell_type": "markdown",
   "source": [
    "捨棄非數值資料"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "799196e2ea9e9abd"
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "df_data_drop = df_data.select_dtypes(include = [\"int64\", \"float64\" ])\n",
    "df_test_drop = df_test.select_dtypes(include = [\"int64\", \"float64\" ])\n",
    "df_data_nmp=df_data_drop.to_numpy()\n",
    "data_splitted_arr_1 , data_splitted_arr_2 = np.vsplit(df_data_nmp, 2)\n",
    "df_label_nmp=df_label.to_numpy()\n",
    "label_splitted_arr_1 , label_splitted_arr_2 = np.vsplit(df_label_nmp, 2)\n",
    "label_splitted_arr_1 = label_splitted_arr_1.ravel()\n",
    "label_splitted_arr_2 = label_splitted_arr_2.ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T18:10:56.205368Z",
     "start_time": "2023-10-20T18:10:56.175566Z"
    }
   },
   "id": "f85dac893e597960"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train Model Without Encode "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea3eb196ac200a41"
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Encode\n",
      "Accuracy: 0.7068\n",
      "Precision: 0.302734375\n",
      "Recall: 0.2919020715630885\n",
      "Confusion Matrix\n",
      "[[3224  714]\n",
      " [ 752  310]]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"X has feature names, but LogisticRegression was fitted without feature names\")\n",
    "model = LogisticRegression( max_iter = 500 )\n",
    "\n",
    "model.fit(data_splitted_arr_1, label_splitted_arr_1)\n",
    "predictions = model.predict(data_splitted_arr_2)\n",
    "\n",
    "model.score(data_splitted_arr_1,label_splitted_arr_1)\n",
    "print ( \"Before Encode\" ) \n",
    "print(\"Accuracy:\" ,metrics.accuracy_score(label_splitted_arr_2, predictions))\n",
    "print(\"Precision:\",metrics.precision_score(label_splitted_arr_2, predictions))\n",
    "print(\"Recall:\" ,metrics.recall_score(label_splitted_arr_2, predictions))\n",
    "\n",
    "coef_model = list(model.coef_)\n",
    "pos_coef = list()\n",
    "for i in range(len(coef_model[0])):\n",
    "    if coef_model[0][i] > 0:\n",
    "        pos_coef.append ( i )\n",
    "\n",
    "matrix = confusion_matrix(label_splitted_arr_2,predictions)\n",
    "print ( \"Confusion Matrix\" )\n",
    "print ( matrix )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T18:10:56.283340Z",
     "start_time": "2023-10-20T18:10:56.187627Z"
    }
   },
   "id": "554a60f1d188cfa9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data PreProcessing and Encode"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f41ac8f0f9974e47"
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "df_data = pd.get_dummies(df_data)\n",
    "df_test = pd.get_dummies(df_test)\n",
    "\n",
    "#df_data = (df_data-df_data.mean())/(df_data.std())\n",
    "#['sales'] = labelencoder.fit_transform ( df_data['sales'] )\n",
    "#df_data['salary'] = labelencoder.fit_transform ( df_data['salary'] )\n",
    "#df_test['sales'] = labelencoder.fit_transform ( df_test['sales'] )\n",
    "#df_test['salary'] = labelencoder.fit_transform ( df_test['salary'] )\n",
    "\n",
    "df_data_nmp=df_data.to_numpy()\n",
    "data_splitted_arr_1 , data_splitted_arr_2 = np.vsplit(df_data_nmp, 2)\n",
    "df_label_nmp=df_label.to_numpy()\n",
    "label_splitted_arr_1 , label_splitted_arr_2 = np.vsplit(df_label_nmp, 2)\n",
    "label_splitted_arr_1 = label_splitted_arr_1.ravel()\n",
    "label_splitted_arr_2 = label_splitted_arr_2.ravel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T18:10:56.330089Z",
     "start_time": "2023-10-20T18:10:56.284258Z"
    }
   },
   "id": "3e8e1373d8aecb2d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a8b2db9215a0e29"
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Encode\n",
      "Accuracy: 0.75\n",
      "Precision: 0.4219269102990033\n",
      "Recall: 0.4783427495291902\n",
      "Confusion Matrix\n",
      "[[3242  696]\n",
      " [ 554  508]]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"X has feature names, but LogisticRegression was fitted without feature names\")\n",
    "model = LogisticRegression( max_iter = 500 )\n",
    "\n",
    "model.fit(data_splitted_arr_1, label_splitted_arr_1)\n",
    "predictions = model.predict(data_splitted_arr_2)\n",
    "\n",
    "model.score(data_splitted_arr_1,label_splitted_arr_1)\n",
    "print ( \"After Encode\" ) \n",
    "print(\"Accuracy:\" ,metrics.accuracy_score(label_splitted_arr_2, predictions))\n",
    "print(\"Precision:\",metrics.precision_score(label_splitted_arr_2, predictions))\n",
    "print(\"Recall:\" ,metrics.recall_score(label_splitted_arr_2, predictions))\n",
    "\n",
    "coef_model = list(model.coef_)\n",
    "pos_coef = list()\n",
    "for i in range(len(coef_model[0])):\n",
    "    if coef_model[0][i] > 0:\n",
    "        pos_coef.append ( i )\n",
    "\n",
    "matrix = confusion_matrix(label_splitted_arr_2,predictions)\n",
    "print ( \"Confusion Matrix\" )\n",
    "print ( matrix )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T18:10:56.495786Z",
     "start_time": "2023-10-20T18:10:56.310845Z"
    }
   },
   "id": "38b07780b40d5b2a"
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "test_predictions = model.predict(df_test)\n",
    "with open('HW2_hr-analytics_test_sol.csv', 'w', newline='') as csvfile:\n",
    "  writer = csv.writer(csvfile)\n",
    "  writer.writerow([\"left\"])\n",
    "  for i in np.nditer(test_predictions):\n",
    "      writer.writerow([i])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-20T18:10:56.536982Z",
     "start_time": "2023-10-20T18:10:56.494958Z"
    }
   },
   "id": "2034d7e2952695a9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
